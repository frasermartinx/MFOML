{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 - Mathematics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CID: 02476922\n",
    "\n",
    "**Colab link:** insert colab link here\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Quickfire questions [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 (True risk / Empirical risk):\n",
    "\n",
    "Let $\\hat{\\mathcal{F}}$ be the full class of functions $f:\\mathcal{X} \\to \\mathcal{Y}$. Assume we have data $(x,y) \\sim D = \\mathcal{X} \\times \\mathcal{Y}$. Consider a loss function $L:\\mathcal{Y}\\times\\mathcal{Y} \\to \\mathbb{R}$.\n",
    "\n",
    "We define the true risk, for a sample from the data generating distribution $\\mathcal{D}$, and a specific function in the full class of functions $\\hat{\\mathcal{F}}$ as the expectation of the loss function over the data generating distribution $R(f) := \\mathbb{E}_D[L(f(x),y)]$. We then seek an $\\hat{F}$ that minimizes this.\n",
    "\n",
    "However, in practical situations, we do not know $D$. Hence we approximate the true risk with the empirical risk, which, for a sample $(x^{(i)},y^{(i)})_{i=1}^N$ assumed to be iid from $D$, is the average loss over the sample (which would converge to the true expectation by LLN), which is defined as $\\hat{R}(f) := \\frac{1}{N}\\sum_{i=1}^N L(f(x^{(i)}),y^{(i)})$.\n",
    "\n",
    "The key difference is that the true risk is the actual thing we are trying to minimize, however it is intractable due to the expectation over the unknown data generating distribution, so we approximate it with the empirical risk, the average loss over a sample. We then seek to minimize the empirical risk instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 ('Large' or 'rich' hypothesis class):\n",
    "\n",
    "In reality, we do not know the true full class of functions $\\hat{\\mathcal{F}}$, so we choose a candidate $\\mathcal{F}$.\n",
    "\n",
    "The benefits of a large hypothesis class are that they can in general contain a much wider class of function than small hypothesis classes, meaning, assuming we choose it wisely, we have more flexibility and potentially more complexity possible, and a bigger space to search for the optimal function in. If we are searching over a bigger space then we are more likely to find a better function to fit the data.\n",
    "\n",
    "However, as seen with the generalisation bound for a finite hypothesis class, the bound for the generalisation error increases logarithmically with the size of the class of functions. That is, the bound for how well the function generalises to unseen data increases logarithmically with the size of the class of functions. Also, there is always the risk of overfitting with a more complex class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 (Dataset splitting):\n",
    "\n",
    "We would not expect the performance of the model on the validation set to perfectly match the performance on unseen data. When we take the training/validation split there is still randomness involved. Perhaps on a different seed a different model would be selected as the best on the validation set. The validation set is also finite, and in this case, small, compared to the training data. Thus, the validation data may have not been able to capture enough variability in the data for it to generalise well to a new test dataset. The selected model may have gotten \"lucky\" on this specific validation set. This is why often there is a training/validation/test split performed, to evaluate performance on data that has not been used to either train the model or tune hyperparamters, since the results can show things such as overfitting/failure to generalise to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (Occamâ€™s razor):\n",
    "\n",
    "Occam's razor in a general sense means that if we have competing hypotheses which have the same performance, we should choose the simplest one. For the specific context of image representation, we should be using low dimensional feature vectors (compressing the data), whilst still being able to represent the important features in the image. For example, in the MNIST dataset, lots of the pixels towards the edge of the images are represented as a 0, since the important distinguishing part of the images are towards the centre, thus we can compress the images by removing the parts of the vector containing the edges of the images (assuming the matrix representation has been flattened to a vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 (Generalisation error):\n",
    "\n",
    "A good model should have a low generalisation error, since, as we estimate it using a second sample (test or validation sample), if this error is low, then it has the meaning that the model can generalise well to unseen data, which is a desirable property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6 (Rademacher complexity pt1):\n",
    "\n",
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7 (Rademacher complexity pt2):\n",
    "\n",
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8 (Regularisation term in the loss function):\n",
    "\n",
    "Sometimes, certain features can dominate predictions, which is not always desirable. If a regularisation term is added, then the model is penalised for choosing parameters that are very large. This helps to reduce overfitting, since then it limits how much each feature can be relied on for prediction. In the case of the Lasso regularisation term, parameter values can actually be shrunk to 0, meaning the optimisation can result in a model of lower dimensionality, which again helps to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 (Momentum gradient descent):\n",
    "\n",
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10 (Adam):\n",
    "\n",
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11 (AdaGrad):\n",
    "\n",
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12 (Decaying Learning Rate):\n",
    "\n",
    "A decaying learning rate is often useful, since without one, the descent algorithm can get stuck around a local/global minimum unable to get any deeper, because the steps it takes towards the minimum are too large, resulting in overshooting. When a decaying learning rate is used, the algorithm takes smaller and smaller steps as the iteration counter increases, which hopefully results in no overshooting. However, this has to be tuned, since there is the risk of the step size decreasing too fast, resulting in the algorithm not moving anywhere, despite not being at a local/global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "***\n",
    "\n",
    "## Part 2: Short-ish proofs [6 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2.1: Bounds on the risk [1 point]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. we have $P[\\hat{R}(f) - R(f) \\ge \\epsilon] = P[\\frac{1}{N}\\sum_{i=1}^N L(f(x^{(i)}),y^{(i)}) - R(f) \\ge \\epsilon] = P[\\frac{1}{N}\\sum_{i=1}^N L_i - R(f) \\ge \\epsilon]$. By the requirements of the lemma, we have that $f:X \\to \\{0,1\\}$. This means that, for a given loss function, there are only 4 possible input states for $L_i$. Hence we can think of $L_i$ as a bounded random variable with 4 possible outputs. Set $a_i = \\min L_i, b_i = \\max L_i$. These will be the same for all $i$. Moreover, $L_i$ are independent since the sample is. Set $S_N = \\sum_{i=1}^N L_i$. Then we have $P[\\hat{R}(f) - R(f) \\ge \\epsilon] = P[\\frac{1}{N}S_N - \\frac{1}{N}\\mathbb{E}[S_N] \\ge \\epsilon] = P[S_N - \\mathbb{E}[S_N] \\ge N\\epsilon]$. Finally, we can use Hoeffding's inequality to get $P[S_N - \\mathbb{E}[S_N] \\ge N\\epsilon] \\le \\exp(\\frac{-2(N\\epsilon)^2}{\\sum_{i=1}^N(b_i-a_i)^2})$. Then, since $a_i,b_i$ are constant, set $(b_i - a_i)^2 = K$, then the exponential simplifies to $\\exp(\\frac{-2(N\\epsilon)^2}{NK}) = \\exp(\\frac{-2 N\\epsilon^2}{K}) =  \\exp(-2 N\\epsilon^2)$ since $\\epsilon$ is arbitrary, and $K$ is constant. This gives us the result $P[\\hat{R}(f) - R(f) \\ge \\epsilon] \\le \\exp(-2 N\\epsilon^2)$, as required. The other inequality follows in the exact same way from the other inequality in the Hoeffding's inequality theorem.\n",
    "\n",
    "\n",
    "2. This result shows that as the size of the dataset, $N$, increases, the probability of the empirical risk being more than some value $\\epsilon$ from the true risk for a given hypothesis $f:X \\to \\{0,1\\}$ decreases. This makes sense, we would expect to converge to the true risk in some way when we collect more data.\n",
    "\n",
    "3. The term $|\\mathcal{F}|$ in theorem 4.8 refers to the size of the function class, or, the number of possible functions we are considering. In the context of the theorem, this term means that generalisation bound for a fixed hypothesis increases logarithmically with the size of the function class. So the more functions we are considering, the greater the potential generalisation error. A balance needs to be attained between the error we are willing to accept and the number of functions we want to potentially consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 2.2: On semi-definiteness [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define $g(t) = f(x+tv)$ for an arbitrary direction $v \\in \\mathbb{R}^d$.\n",
    "\n",
    "\n",
    "\n",
    "To show $g$ is convex, let $t_1,t_2 \\in \\mathbb{R}$ and $\\lambda \\in [0,1]$. Then, using its relation to $f$, and the convexity of $f$:\n",
    "\n",
    "$g(\\lambda t_1 + (1-\\lambda)t_2) = f(x + (\\lambda t_1 + (1-\\lambda)t_2)v) = f(x + \\lambda t_1 v + t_2 v - \\lambda t_2 v)  = f(x + \\lambda t_1 v + t_2 v - \\lambda t_2 v + \\lambda x - \\lambda x) = f(\\lambda (x+t_1 v) + (1-\\lambda)(x+t_2 v)) \\le \\lambda f(x+t_1 v) + (1- \\lambda)f(x + t_2 v) = \\lambda g(t_1) + (1- \\lambda)g(t_2)$\n",
    "\n",
    "Hence $g$ is convex in $\\mathbb{R}$.\n",
    "\n",
    "To show differentiability, we will compute the derivative and show it exists. Letting $x+tv := p(t)$:\n",
    "\n",
    "$g'(t) = \\frac{d}{dt}f(x+tv) = \\sum_i\\frac{\\partial f}{\\partial p_i} \\frac{dp_i}{dt} = \\sum_i[\\nabla f(p(t))]_i v_i =  v \\cdot \\nabla f(p(t)) $.\n",
    "\n",
    "Hence $g$ is once differentiable since $f$ is once differentiable (ie $\\nabla f$ exists).\n",
    "\n",
    "$g''(t) = \\frac{d}{dt}(\\sum_i\\frac{\\partial f}{\\partial p_i} v_i) = \\sum_i \\frac{d}{dt}(\\frac{\\partial f}{\\partial p_i} v_i) = \\sum_i (\\frac{d}{dt}(\\frac{\\partial f}{\\partial p_i}) + \\frac{\\partial f}{\\partial p_i} \\frac{d}{dt}(v_i)) = \\sum_i \\sum_j \\frac{\\partial f}{\\partial p_i \\partial p_j} \\frac{d p_j}{dt} v_i = \\sum_i \\sum_j \\frac{\\partial f}{\\partial p_i \\partial p_j} v_j v_i $\n",
    "\n",
    "$\\implies g''(t)= v^T H v$, where $H$ is the hessian of $f$. Hence $g$ is twice differentiable since $f$ is twice differeniable (ie $H$ exists).\n",
    "\n",
    "We know for $d = 1$, the implication holds, hence, since $g:\\mathbb{R} \\to \\mathbb{R}$, $g$ convex $\\implies g''(t) \\ge 0 \\ \\forall \\ t$.\n",
    "\n",
    "In particular, if we let $t = 0$, we get $0 \\le g''(0) = v^T H v = v^T \\nabla ^2 f(x) v$\n",
    "\n",
    "$\\implies v^T \\nabla ^2 f(x) v \\ge 0 \\ \\forall \\ v \\in \\mathbb{R}^d$, since $v$ was chosen arbitrarily.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 2.3: A quick recap of momentum [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the analysis with $f(x) = \\frac{1}{2}x^TSx - b^T x, x \\in \\mathbb{R}^d$, and $x^*$ the optimum.\n",
    "\n",
    "When we make the change of basis as specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Question 2.4: Convergence proof [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "\n",
    "The evolution for netwon's method for gradient descent is as follows:\n",
    "$x_{k+1} = x_k - (\\nabla ^ 2 f(x_k))^{-1} \\nabla f(x_k)$.\n",
    "\n",
    "This basically works by approximating the function $f$ by a quadratic function (using a taylor approximation), and then minimizing that approximation at each iteration wrt the step, which leads to taking steps towards the overall local/global minimum of the function.\n",
    "\n",
    "2. \n",
    "\n",
    "$f(x) = \\frac{1}{2}x^T Q x + b^T x + c$, with $x \\in \\mathbb{R}^d$ and $Q$ is positive definite.\n",
    "\n",
    "Here, $f$ is a quadratic function, so the approximation is exact. The minimum is given when $\\nabla f(x) = 0$, which gives $Qx + b = 0 \\implies x = -Q^{-1}b$ is the minimum.\n",
    "\n",
    "Nevertheless, given a current state $x_k$, we have $\\nabla f(x_k) = Qx_k + b$, and $\\nabla^2 f(x_k) = Q$.\n",
    "\n",
    "Thus, when making the step as per newton's method, we have:\n",
    "\n",
    "$x_{k+1} = x_k - (\\nabla ^ 2 f(x_k))^{-1} \\nabla f(x_k) = x_k - Q^{-1}( Qx_k + b) = - Q^{-1}b$, hence the algorithm converges in one iteration regardless of where we start.\n",
    "\n",
    "3. \n",
    "\n",
    "Newton's method makes a quadratic approximation using a taylor series around $f$. However, when $f$ itself is quadratic, the approximation is exact. Thus, since in each iteration we are setting the next x location to be that which minimizes the quadratic approximation, we obtain the minimum in one step as the function $f$ itself is exactly the approximation.\n",
    "\n",
    "\n",
    "4. \n",
    "\n",
    "Using Newton's iterative step, $x_{1} = x_0 - (\\nabla ^ 2 f(x_0))^{-1} \\nabla f(x_0)$. \n",
    "\n",
    "$\\implies x_{1} - x^* = x_0 - (\\nabla ^ 2 f(x_0))^{-1} \\nabla f(x_0) - x^*$\n",
    "\n",
    "\n",
    "Then, by thinking of $x_0 - x^*$ as $I(x_0- x^*)$, and noting that $\\nabla ^ 2 f(x_0)$ is invertible:\n",
    "\n",
    "$x_{1} - x^*= (\\nabla ^ 2 f(x_0))^{-1}(\\nabla ^ 2 f(x_0))(x_0 - x^*) - (\\nabla ^ 2 f(x_0))^{-1} \\nabla f(x_0)$\n",
    "\n",
    "$\\implies x_{1} - x^*= (\\nabla ^ 2 f(x_0))^{-1}(\\nabla ^ 2 f(x_0)(x_0 - x^*) - \\nabla f(x_0))$.\n",
    "\n",
    "Then, by using Lemma 0.1, we obtain (noting that $(\\nabla ^ 2 f(x_0))^{-1}$ is a square matrix, and is continuous for all $x$, since it is 3 times continuously differentiable):\n",
    "\n",
    "$ ||x_1 - x^*|| \\le ||(\\nabla ^ 2 f(x_0))^{-1}|| \\ || \\nabla ^ 2 f(x_0)(x_0 - x^*) - \\nabla f(x_0) || $, as required.\n",
    "\n",
    "5.\n",
    "\n",
    " By assumption $f \\in C^3$ and $\\nabla ^2 f(x^*)$ is invertible, hence, by lemma 0.2, there exist scalars $\\epsilon, c_1$ such that for all $x_0 \\in B(x^*,\\epsilon)$, $||(\\nabla ^2 f(x^*))^{-1}|| \\le c_1 $.\n",
    "\n",
    "Also, if we consider the taylor series expansion of $\\nabla f$ about $x_0$, we obtain:\n",
    "\n",
    "$\\nabla f(x)$ = $\\nabla f(x_0) + \\nabla^2 f(x_0)(x-x_0) + O(||x-x_0||^2)$\n",
    "\n",
    "This remainder will contain third derivatives since $f \\in C^3$, these derivatives are continuous and hence bounded on $B(x^*,\\epsilon)$. Then, if we choose $x = x^*$, we obtain (recalling $\\nabla f(x^*) = 0$):\n",
    "\n",
    "$ \\nabla^2 f(x_0)(x_0-x^*) -\\nabla f(x_0)= O(||x^*-x_0||^2)$\n",
    "\n",
    "$\\implies ||\\nabla^2 f(x_0)(x_0-x^*) +\\nabla f(x_0)|| \\le c_2||x_0-x^*||^2$\n",
    "\n",
    "Then, applying these two bounds to step 4. we get the result, there exists an $\\epsilon > 0$ st:\n",
    "\n",
    "$||x_1 - x^*|| \\le c_1c_2||x_0 - x^*||^2$ for all $x_0 \\in B(x^*,\\epsilon)$\n",
    "\n",
    "\n",
    "6.\n",
    "\n",
    "Consider $x_0 \\in B(x^*, \\epsilon)$ such that $||x_0 - x^*|| \\le \\frac{\\alpha}{c_1c_2}$, with $\\alpha \\in (0,1)$, then, $\\epsilon \\le \\frac{\\alpha}{c_1c_2}$, and:\n",
    "\n",
    "$||x_1 - x^*|| \\le c_1 c_2 (\\frac{\\alpha^2}{c_1^2c_2^2}) = \\frac{\\alpha^2}{c_1c_2} \\le \\frac{\\alpha}{c_1c_2}$ since $\\alpha \\in (0,1)$, as required.\n",
    "\n",
    "Also, following this result, we have that $x_1 \\in B(x^*,\\epsilon)$, by definition of the ball.\n",
    "\n",
    "7.\n",
    "\n",
    "By induction, using the same method we just presented, $||x_{k+1} -x^*|| \\le c_1c_2||x_{k}-x^*||^2$.\n",
    "\n",
    "Since  $||x_k - x^*|| \\le \\frac{\\alpha}{c_1c_2}$, we have:\n",
    "\n",
    "$||x_{k+1} -x^*|| \\le \\alpha ||x_{k}-x^*||$ , for all $x_{k} \\in B(x^*, \\epsilon)$ (again meaning $x_{k+1} \\in B(x^*, \\epsilon)$)\n",
    "\n",
    "8. \n",
    "\n",
    "Since $\\alpha \\in (0,1)$, this distance will shrink across the iterations, meaning $x_k \\to x^*$ as $k \\to \\infty$.\n",
    "\n",
    "Also, we have that the convergence is quadratic, since $||x_{k+1} -x^*|| \\le c_1c_2||x_{k}-x^*||^2$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Part 3: A deeper dive into neural network implementations [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download datasets\n",
    "train_set_mnist = torchvision.datasets.MNIST(root=\"../../\", download=True,\n",
    "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set_mnist = torchvision.datasets.MNIST(root=\"../../\",download=True,\n",
    "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),)\n",
    "\n",
    "train_set_cifar = torchvision.datasets.CIFAR10(root=\"../../\", download=True,\n",
    "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set_cifar = torchvision.datasets.CIFAR10(root=\"../../\",download=True,\n",
    "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1f33a965f30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "SEED = 2476922\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess MNIST, we will be scaling the inputs to (0,1)\n",
    "print(torch.max(train_set_mnist[100][0]))\n",
    "#it appears the data is already scaled to the correct scaling\n",
    "torch.max(test_set_mnist[100][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Part 3.1: Implementations [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the Network class, that initializes 5 types of layers, with the Relu layer and hidden layer used multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1 ###\n",
    "\n",
    "class Network(nn.Module):\n",
    "    #initialise the layers etc\n",
    "    def __init__(self, dim, nclass, width, depth):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            dim - Dimension of the flattened input\n",
    "            nclass - Number of classes we want to predict\n",
    "            width - the width in each layer, same for all layers\n",
    "            depth - the depth of the network    \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        #assign depth as an attribute\n",
    "        self.depth = depth\n",
    "        # The code below defines the layers for our model, which includes 5 different types of layer\n",
    "        # The hidden layer and relu layer are used multiple times\n",
    "        layers = []\n",
    "        #input and flatten\n",
    "        layers += [nn.Flatten(),nn.Linear(dim,width),nn.ReLU()]\n",
    "        #only put hidden layers in if depth is more than 1:\n",
    "        for i in range(self.depth-1):\n",
    "            layers += [nn.Linear(width,width), nn.ReLU()]\n",
    "        #output\n",
    "        layers += [nn.Linear(width,nclass)]\n",
    "\n",
    "        #sequential\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    #this gets called on call\n",
    "    def forward(self,input):\n",
    "        #input = input.view(input.size(0), -1)\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the function to load the data, which is already preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 2 ###\n",
    "\n",
    "def loading_data(batch_size,train_set,test_set):\n",
    "    #already preprocessed\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    return trainloader,testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the train and test epochs, taking care to return the average loss over the entire epoch, not just the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3 ###\n",
    "\n",
    "def train_epoch(trainloader, net, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Train a model on the training set of FashionMNIST\n",
    "\n",
    "    Inputs:\n",
    "        trainloader - DataLoader object of the dataset to train on \n",
    "        net - Object of Network\n",
    "        optimizer - the optimizer object\n",
    "        criterion - the loss function\n",
    "    \"\"\"\n",
    "    #set the net to train:\n",
    "    net.train()\n",
    "    loss_count,count = 0,0\n",
    "    #iterate\n",
    "    for imgs, labels in trainloader:\n",
    "        #send to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        #forward pass\n",
    "        preds = net(imgs)\n",
    "        #find loss\n",
    "        loss = criterion(preds, labels)\n",
    "        #back pass\n",
    "        loss.backward()\n",
    "        #update weights\n",
    "        optimizer.step()\n",
    "        #now compute the additive loss for the epoch (we could do this by specifying reduce = sum in the metric, but this makes things unstable)\n",
    "        #we do batch size in case the batch size does not divide the data size\n",
    "        #loss fn returns batch average on default\n",
    "        batch_size =  labels.shape[0] \n",
    "        loss_count += loss * batch_size\n",
    "        count += batch_size\n",
    "        \n",
    "    return loss_count/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 4 ###\n",
    "\n",
    "\n",
    "def test_epoch(testloader,net,criterion):\n",
    "    \"\"\"\n",
    "    Test a model on a specified dataset.\n",
    "\n",
    "    Inputs:\n",
    "        testloader - DataLoader object of the dataset to test on (validation or test)\n",
    "        net - Trained model of type Network\n",
    "        criterion - the loss function\n",
    "    \"\"\"\n",
    "    #set to evaluate\n",
    "    net.eval()\n",
    "    true_preds, count,loss_count = 0., 0, 0 \n",
    "    for imgs, labels in testloader:\n",
    "        #send to GPU\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)   \n",
    "        #we do not use the gradient\n",
    "        with torch.no_grad():\n",
    "            #find the predicted label\n",
    "            preds = net(imgs)\n",
    "            #now compute the additive loss for the epoch (we could do this by specifying reduce = sum in the metric, but this makes things unstable)\n",
    "            #we do batch size in case the batch size does not divide the data size\n",
    "            #loss fn returns batch average on default\n",
    "            batch_size =  labels.shape[0] \n",
    "            loss_count += criterion(preds, labels) * batch_size\n",
    "            count += batch_size\n",
    "            \n",
    "            #change to label\n",
    "            preds = preds.argmax(dim=-1)\n",
    "\n",
    "            # add the number of correct predictions in the batch to the running total\n",
    "            true_preds += (preds == labels).sum().item()\n",
    "            \n",
    "            \n",
    "    test_err = 1 - true_preds / count\n",
    "    avg_loss = loss_count/count\n",
    "    return  test_err,avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the function that actually trains the model, given the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 5 ###\n",
    "\n",
    "#defining hyperparameters that will be used to initialise the model object\n",
    "\n",
    "#MNIST\n",
    "dim = 784\n",
    "nclass = 10\n",
    "#we set \n",
    "width = 256\n",
    "depth = 1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model that will train the network\n",
    "def train_model(net,batch_size,lr,num_epochs,train,test):\n",
    "    \"\"\"\n",
    "        Train and test the given model using the other hyperparameters \n",
    "\n",
    "        Inputs:\n",
    "            net - model of type Network\n",
    "            batch_size - the batch size\n",
    "            lr - learning rate\n",
    "            num_epochs - number of epochs to perform\n",
    "            train - the training data\n",
    "            test - the test data\n",
    "    \"\"\"\n",
    "    #define loss, optimizer\n",
    "    #we set loss to be sum otherwise it will average over each batch\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(),lr = lr)\n",
    "    #batch and process data\n",
    "    train_load, test_load = loading_data(batch_size,train,test)\n",
    "    # setup variables to store metrics at each iteration\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "    test_err_history = []\n",
    "    #perform epochs\n",
    "    for epoch in range(0,num_epochs):\n",
    "\n",
    "        #train\n",
    "        train_loss =  train_epoch(train_load, net, optimizer, loss_module)\n",
    "        #test recording loss and error:\n",
    "        test_err,test_loss = test_epoch(test_load,net,loss_module)\n",
    "        print(f\"Epoch: {(epoch+1):03} | Train Loss: {train_loss:.04} |Test Loss: {test_loss:.04} | Test Error: {test_err:.04}\")\n",
    "        #record metrics\n",
    "        train_loss_history.append(train_loss.item())\n",
    "        test_loss_history.append(test_loss.item())\n",
    "        test_err_history.append(test_err)\n",
    "    #for later parts in the question, we return the history of each metric:\n",
    "    return train_loss_history, test_loss_history, test_err_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Part 3.2: Numerical exploration [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 ###\n",
    "For this part of the question, we set the width of each layer to be 256, we shall use ADAM as our optimizer, with the learning rate as 0.1, we shall run for 100 epochs each time, with a batch size of 1024, based on the size of the dataset. Since we are working with the MNIST dataset, we set dim = 28*28 = 784, and nclass = 10. We shall vary the depth in $\\{1,5,10\\}$ as stated in the question.\n",
    "\n",
    "Upon running the training function, we receive the loss history for both training and testing, as well as the error history for testing. In the table we display the best test loss and the corresponding training loss for that epoch, for each depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General MNIST Hyperparameters\n",
    "dim = 784\n",
    "nclass = 10\n",
    "\n",
    "# Task 6 fixed hyperparameters\n",
    "width = 256\n",
    "lr = 0.01\n",
    "batch_size = 1024\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train Loss: 0.3757 |Test Loss: 0.1619 | Test Error: 0.0504\n",
      "Epoch: 002 | Train Loss: 0.1262 |Test Loss: 0.1089 | Test Error: 0.0324\n",
      "Epoch: 003 | Train Loss: 0.08326 |Test Loss: 0.09468 | Test Error: 0.0296\n",
      "Epoch: 004 | Train Loss: 0.05971 |Test Loss: 0.07999 | Test Error: 0.0253\n",
      "Epoch: 005 | Train Loss: 0.04166 |Test Loss: 0.07161 | Test Error: 0.0203\n",
      "Epoch: 006 | Train Loss: 0.03111 |Test Loss: 0.0786 | Test Error: 0.0243\n",
      "Epoch: 007 | Train Loss: 0.02485 |Test Loss: 0.07299 | Test Error: 0.0217\n",
      "Epoch: 008 | Train Loss: 0.02219 |Test Loss: 0.07549 | Test Error: 0.0216\n",
      "Epoch: 009 | Train Loss: 0.01413 |Test Loss: 0.08333 | Test Error: 0.0229\n",
      "Epoch: 010 | Train Loss: 0.01049 |Test Loss: 0.07481 | Test Error: 0.0202\n",
      "Epoch: 011 | Train Loss: 0.007043 |Test Loss: 0.07832 | Test Error: 0.0204\n",
      "Epoch: 012 | Train Loss: 0.004385 |Test Loss: 0.07259 | Test Error: 0.0186\n",
      "Epoch: 013 | Train Loss: 0.004185 |Test Loss: 0.07954 | Test Error: 0.0202\n",
      "Epoch: 014 | Train Loss: 0.003207 |Test Loss: 0.07491 | Test Error: 0.0196\n",
      "Epoch: 015 | Train Loss: 0.002218 |Test Loss: 0.08097 | Test Error: 0.0196\n",
      "Epoch: 016 | Train Loss: 0.001337 |Test Loss: 0.07466 | Test Error: 0.0184\n",
      "Epoch: 017 | Train Loss: 0.000851 |Test Loss: 0.07482 | Test Error: 0.0181\n",
      "Epoch: 018 | Train Loss: 0.0005567 |Test Loss: 0.07626 | Test Error: 0.0189\n",
      "Epoch: 019 | Train Loss: 0.0006846 |Test Loss: 0.07949 | Test Error: 0.0196\n",
      "Epoch: 020 | Train Loss: 0.000517 |Test Loss: 0.07756 | Test Error: 0.0183\n",
      "Epoch: 021 | Train Loss: 0.0003432 |Test Loss: 0.07873 | Test Error: 0.0188\n",
      "Epoch: 022 | Train Loss: 0.0002908 |Test Loss: 0.07965 | Test Error: 0.0183\n",
      "Epoch: 023 | Train Loss: 0.0002631 |Test Loss: 0.07974 | Test Error: 0.0186\n",
      "Epoch: 024 | Train Loss: 0.0002371 |Test Loss: 0.07988 | Test Error: 0.0183\n",
      "Epoch: 025 | Train Loss: 0.0002197 |Test Loss: 0.08087 | Test Error: 0.0186\n",
      "Epoch: 026 | Train Loss: 0.0002028 |Test Loss: 0.08091 | Test Error: 0.0185\n",
      "Epoch: 027 | Train Loss: 0.0001893 |Test Loss: 0.0815 | Test Error: 0.0183\n",
      "Epoch: 028 | Train Loss: 0.0001785 |Test Loss: 0.08207 | Test Error: 0.0182\n",
      "Epoch: 029 | Train Loss: 0.0001702 |Test Loss: 0.0819 | Test Error: 0.0184\n",
      "Epoch: 030 | Train Loss: 0.000158 |Test Loss: 0.08323 | Test Error: 0.0184\n",
      "Epoch: 031 | Train Loss: 0.0001497 |Test Loss: 0.08293 | Test Error: 0.0184\n",
      "Epoch: 032 | Train Loss: 0.0001393 |Test Loss: 0.08332 | Test Error: 0.0185\n",
      "Epoch: 033 | Train Loss: 0.0001323 |Test Loss: 0.08378 | Test Error: 0.0185\n",
      "Epoch: 034 | Train Loss: 0.0001244 |Test Loss: 0.08436 | Test Error: 0.0182\n",
      "Epoch: 035 | Train Loss: 0.0001182 |Test Loss: 0.08437 | Test Error: 0.0184\n",
      "Epoch: 036 | Train Loss: 0.0001126 |Test Loss: 0.08467 | Test Error: 0.0184\n",
      "Epoch: 037 | Train Loss: 0.0001067 |Test Loss: 0.08525 | Test Error: 0.0184\n",
      "Epoch: 038 | Train Loss: 0.0001009 |Test Loss: 0.08582 | Test Error: 0.0185\n",
      "Epoch: 039 | Train Loss: 9.608e-05 |Test Loss: 0.08585 | Test Error: 0.0184\n",
      "Epoch: 040 | Train Loss: 9.124e-05 |Test Loss: 0.08611 | Test Error: 0.0181\n",
      "Epoch: 041 | Train Loss: 8.631e-05 |Test Loss: 0.0866 | Test Error: 0.0181\n",
      "Epoch: 042 | Train Loss: 8.222e-05 |Test Loss: 0.08697 | Test Error: 0.0179\n",
      "Epoch: 043 | Train Loss: 7.905e-05 |Test Loss: 0.08765 | Test Error: 0.0181\n",
      "Epoch: 044 | Train Loss: 7.506e-05 |Test Loss: 0.08781 | Test Error: 0.0183\n",
      "Epoch: 045 | Train Loss: 7.202e-05 |Test Loss: 0.08828 | Test Error: 0.0183\n",
      "Epoch: 046 | Train Loss: 6.785e-05 |Test Loss: 0.08844 | Test Error: 0.0183\n",
      "Epoch: 047 | Train Loss: 6.492e-05 |Test Loss: 0.0886 | Test Error: 0.0185\n",
      "Epoch: 048 | Train Loss: 6.239e-05 |Test Loss: 0.08948 | Test Error: 0.0179\n",
      "Epoch: 049 | Train Loss: 5.996e-05 |Test Loss: 0.08967 | Test Error: 0.0184\n",
      "Epoch: 050 | Train Loss: 5.674e-05 |Test Loss: 0.08956 | Test Error: 0.0183\n",
      "Epoch: 051 | Train Loss: 5.424e-05 |Test Loss: 0.09006 | Test Error: 0.0184\n",
      "Epoch: 052 | Train Loss: 5.207e-05 |Test Loss: 0.09046 | Test Error: 0.0181\n",
      "Epoch: 053 | Train Loss: 4.974e-05 |Test Loss: 0.09096 | Test Error: 0.0181\n",
      "Epoch: 054 | Train Loss: 4.773e-05 |Test Loss: 0.09103 | Test Error: 0.0178\n",
      "Epoch: 055 | Train Loss: 4.576e-05 |Test Loss: 0.09111 | Test Error: 0.0184\n",
      "Epoch: 056 | Train Loss: 4.37e-05 |Test Loss: 0.09175 | Test Error: 0.0183\n",
      "Epoch: 057 | Train Loss: 4.213e-05 |Test Loss: 0.09183 | Test Error: 0.0183\n",
      "Epoch: 058 | Train Loss: 4.038e-05 |Test Loss: 0.09225 | Test Error: 0.0183\n",
      "Epoch: 059 | Train Loss: 3.886e-05 |Test Loss: 0.09275 | Test Error: 0.0179\n",
      "Epoch: 060 | Train Loss: 3.723e-05 |Test Loss: 0.09285 | Test Error: 0.0183\n",
      "Epoch: 061 | Train Loss: 3.562e-05 |Test Loss: 0.09348 | Test Error: 0.0183\n",
      "Epoch: 062 | Train Loss: 3.441e-05 |Test Loss: 0.09372 | Test Error: 0.0181\n",
      "Epoch: 063 | Train Loss: 3.289e-05 |Test Loss: 0.09368 | Test Error: 0.0182\n",
      "Epoch: 064 | Train Loss: 3.147e-05 |Test Loss: 0.09406 | Test Error: 0.0182\n",
      "Epoch: 065 | Train Loss: 3.03e-05 |Test Loss: 0.09425 | Test Error: 0.0185\n",
      "Epoch: 066 | Train Loss: 2.912e-05 |Test Loss: 0.09482 | Test Error: 0.0182\n",
      "Epoch: 067 | Train Loss: 2.801e-05 |Test Loss: 0.09514 | Test Error: 0.0183\n",
      "Epoch: 068 | Train Loss: 2.707e-05 |Test Loss: 0.09502 | Test Error: 0.0182\n",
      "Epoch: 069 | Train Loss: 2.592e-05 |Test Loss: 0.0955 | Test Error: 0.0183\n",
      "Epoch: 070 | Train Loss: 2.495e-05 |Test Loss: 0.09563 | Test Error: 0.0183\n",
      "Epoch: 071 | Train Loss: 2.408e-05 |Test Loss: 0.09644 | Test Error: 0.0183\n",
      "Epoch: 072 | Train Loss: 2.327e-05 |Test Loss: 0.09637 | Test Error: 0.0183\n",
      "Epoch: 073 | Train Loss: 2.237e-05 |Test Loss: 0.09656 | Test Error: 0.0183\n",
      "Epoch: 074 | Train Loss: 2.134e-05 |Test Loss: 0.09704 | Test Error: 0.0182\n",
      "Epoch: 075 | Train Loss: 2.053e-05 |Test Loss: 0.09734 | Test Error: 0.0182\n",
      "Epoch: 076 | Train Loss: 1.997e-05 |Test Loss: 0.09763 | Test Error: 0.0184\n",
      "Epoch: 077 | Train Loss: 1.908e-05 |Test Loss: 0.09794 | Test Error: 0.0184\n",
      "Epoch: 078 | Train Loss: 1.851e-05 |Test Loss: 0.09801 | Test Error: 0.018\n",
      "Epoch: 079 | Train Loss: 1.784e-05 |Test Loss: 0.09846 | Test Error: 0.0182\n",
      "Epoch: 080 | Train Loss: 1.708e-05 |Test Loss: 0.09883 | Test Error: 0.0183\n",
      "Epoch: 081 | Train Loss: 1.654e-05 |Test Loss: 0.09869 | Test Error: 0.0183\n",
      "Epoch: 082 | Train Loss: 1.582e-05 |Test Loss: 0.09895 | Test Error: 0.0182\n",
      "Epoch: 083 | Train Loss: 1.541e-05 |Test Loss: 0.09929 | Test Error: 0.0182\n",
      "Epoch: 084 | Train Loss: 1.481e-05 |Test Loss: 0.0998 | Test Error: 0.0183\n",
      "Epoch: 085 | Train Loss: 1.425e-05 |Test Loss: 0.09993 | Test Error: 0.0183\n",
      "Epoch: 086 | Train Loss: 1.375e-05 |Test Loss: 0.1003 | Test Error: 0.0183\n",
      "Epoch: 087 | Train Loss: 1.329e-05 |Test Loss: 0.1007 | Test Error: 0.0181\n",
      "Epoch: 088 | Train Loss: 1.28e-05 |Test Loss: 0.1006 | Test Error: 0.0182\n",
      "Epoch: 089 | Train Loss: 1.229e-05 |Test Loss: 0.1011 | Test Error: 0.0182\n",
      "Epoch: 090 | Train Loss: 1.19e-05 |Test Loss: 0.1012 | Test Error: 0.0184\n",
      "Epoch: 091 | Train Loss: 1.154e-05 |Test Loss: 0.1015 | Test Error: 0.0183\n",
      "Epoch: 092 | Train Loss: 1.111e-05 |Test Loss: 0.1016 | Test Error: 0.0182\n",
      "Epoch: 093 | Train Loss: 1.07e-05 |Test Loss: 0.102 | Test Error: 0.018\n",
      "Epoch: 094 | Train Loss: 1.036e-05 |Test Loss: 0.1024 | Test Error: 0.0184\n",
      "Epoch: 095 | Train Loss: 9.973e-06 |Test Loss: 0.1028 | Test Error: 0.0183\n",
      "Epoch: 096 | Train Loss: 9.661e-06 |Test Loss: 0.1027 | Test Error: 0.0183\n",
      "Epoch: 097 | Train Loss: 9.278e-06 |Test Loss: 0.103 | Test Error: 0.0183\n",
      "Epoch: 098 | Train Loss: 8.949e-06 |Test Loss: 0.1035 | Test Error: 0.0183\n",
      "Epoch: 099 | Train Loss: 8.712e-06 |Test Loss: 0.1039 | Test Error: 0.0184\n",
      "Epoch: 100 | Train Loss: 8.413e-06 |Test Loss: 0.1039 | Test Error: 0.0182\n"
     ]
    }
   ],
   "source": [
    "# depth = 1 parameters\n",
    "depth = 1\n",
    "# initialize model\n",
    "net1 = Network(dim,nclass,width,depth)\n",
    "#send to GPU\n",
    "net1 = net1.to(device)\n",
    "#train it\n",
    "D1 = train_model(net1,batch_size,lr,num_epochs,train_set_mnist,test_set_mnist)\n",
    "#best = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss for depth = 1: 0.04166, best test loss for depth = 1: 0.07161\n"
     ]
    }
   ],
   "source": [
    "min = np.argmin(D1[1])\n",
    "print(f\"Best training loss for depth = 1: {D1[0][min]:.04}, best test loss for depth = 1: {D1[1][min]:.04}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f37fef5390>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(D1[0])\n",
    "plt.plot(D1[1])\n",
    "plt.plot(D1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train Loss: 0.8105 |Test Loss: 0.2243 | Test Error: 0.063\n",
      "Epoch: 002 | Train Loss: 0.1653 |Test Loss: 0.139 | Test Error: 0.0387\n",
      "Epoch: 003 | Train Loss: 0.1121 |Test Loss: 0.1285 | Test Error: 0.0345\n",
      "Epoch: 004 | Train Loss: 0.08904 |Test Loss: 0.1214 | Test Error: 0.0322\n",
      "Epoch: 005 | Train Loss: 0.07137 |Test Loss: 0.122 | Test Error: 0.0327\n",
      "Epoch: 006 | Train Loss: 0.05949 |Test Loss: 0.1112 | Test Error: 0.0293\n",
      "Epoch: 007 | Train Loss: 0.05729 |Test Loss: 0.119 | Test Error: 0.0304\n",
      "Epoch: 008 | Train Loss: 0.04866 |Test Loss: 0.1189 | Test Error: 0.029\n",
      "Epoch: 009 | Train Loss: 0.04195 |Test Loss: 0.1072 | Test Error: 0.0253\n",
      "Epoch: 010 | Train Loss: 0.04042 |Test Loss: 0.1089 | Test Error: 0.0266\n",
      "Epoch: 011 | Train Loss: 0.03594 |Test Loss: 0.114 | Test Error: 0.0263\n",
      "Epoch: 012 | Train Loss: 0.02984 |Test Loss: 0.1174 | Test Error: 0.023\n",
      "Epoch: 013 | Train Loss: 0.02887 |Test Loss: 0.1376 | Test Error: 0.0271\n",
      "Epoch: 014 | Train Loss: 0.03272 |Test Loss: 0.1169 | Test Error: 0.0262\n",
      "Epoch: 015 | Train Loss: 0.03141 |Test Loss: 0.1265 | Test Error: 0.0252\n",
      "Epoch: 016 | Train Loss: 0.02988 |Test Loss: 0.1331 | Test Error: 0.0249\n",
      "Epoch: 017 | Train Loss: 0.02632 |Test Loss: 0.122 | Test Error: 0.0233\n",
      "Epoch: 018 | Train Loss: 0.02972 |Test Loss: 0.1238 | Test Error: 0.0261\n",
      "Epoch: 019 | Train Loss: 0.02388 |Test Loss: 0.1584 | Test Error: 0.0269\n",
      "Epoch: 020 | Train Loss: 0.02881 |Test Loss: 0.1362 | Test Error: 0.0234\n",
      "Epoch: 021 | Train Loss: 0.02269 |Test Loss: 0.1271 | Test Error: 0.0224\n",
      "Epoch: 022 | Train Loss: 0.03104 |Test Loss: 0.1337 | Test Error: 0.0273\n",
      "Epoch: 023 | Train Loss: 0.02481 |Test Loss: 0.1171 | Test Error: 0.0235\n",
      "Epoch: 024 | Train Loss: 0.01922 |Test Loss: 0.133 | Test Error: 0.0247\n",
      "Epoch: 025 | Train Loss: 0.02091 |Test Loss: 0.1212 | Test Error: 0.0243\n",
      "Epoch: 026 | Train Loss: 0.01881 |Test Loss: 0.1443 | Test Error: 0.0252\n",
      "Epoch: 027 | Train Loss: 0.01756 |Test Loss: 0.162 | Test Error: 0.0243\n",
      "Epoch: 028 | Train Loss: 0.02145 |Test Loss: 0.1399 | Test Error: 0.0244\n",
      "Epoch: 029 | Train Loss: 0.0251 |Test Loss: 0.1506 | Test Error: 0.0229\n",
      "Epoch: 030 | Train Loss: 0.02803 |Test Loss: 0.1549 | Test Error: 0.0226\n",
      "Epoch: 031 | Train Loss: 0.03085 |Test Loss: 0.1677 | Test Error: 0.0247\n",
      "Epoch: 032 | Train Loss: 0.05666 |Test Loss: 0.1686 | Test Error: 0.0302\n",
      "Epoch: 033 | Train Loss: 0.03301 |Test Loss: 0.1524 | Test Error: 0.0238\n",
      "Epoch: 034 | Train Loss: 0.02291 |Test Loss: 0.1649 | Test Error: 0.0235\n",
      "Epoch: 035 | Train Loss: 0.02708 |Test Loss: 0.1589 | Test Error: 0.0244\n",
      "Epoch: 036 | Train Loss: 0.02293 |Test Loss: 0.158 | Test Error: 0.024\n",
      "Epoch: 037 | Train Loss: 0.01685 |Test Loss: 0.1518 | Test Error: 0.0219\n",
      "Epoch: 038 | Train Loss: 0.01182 |Test Loss: 0.1632 | Test Error: 0.0218\n",
      "Epoch: 039 | Train Loss: 0.01809 |Test Loss: 0.1775 | Test Error: 0.0244\n",
      "Epoch: 040 | Train Loss: 0.02442 |Test Loss: 0.1505 | Test Error: 0.0227\n",
      "Epoch: 041 | Train Loss: 0.01754 |Test Loss: 0.1576 | Test Error: 0.0231\n",
      "Epoch: 042 | Train Loss: 0.01342 |Test Loss: 0.2222 | Test Error: 0.0244\n",
      "Epoch: 043 | Train Loss: 0.01574 |Test Loss: 0.1461 | Test Error: 0.0212\n",
      "Epoch: 044 | Train Loss: 0.01791 |Test Loss: 0.1908 | Test Error: 0.0241\n",
      "Epoch: 045 | Train Loss: 0.02095 |Test Loss: 0.1679 | Test Error: 0.0212\n",
      "Epoch: 046 | Train Loss: 0.02347 |Test Loss: 0.1663 | Test Error: 0.0237\n",
      "Epoch: 047 | Train Loss: 0.02134 |Test Loss: 0.1731 | Test Error: 0.0232\n",
      "Epoch: 048 | Train Loss: 0.02337 |Test Loss: 0.2008 | Test Error: 0.0257\n",
      "Epoch: 049 | Train Loss: 0.02953 |Test Loss: 0.183 | Test Error: 0.0249\n",
      "Epoch: 050 | Train Loss: 0.03141 |Test Loss: 0.1796 | Test Error: 0.0239\n",
      "Epoch: 051 | Train Loss: 0.02712 |Test Loss: 0.1762 | Test Error: 0.0256\n",
      "Epoch: 052 | Train Loss: 0.03524 |Test Loss: 0.1736 | Test Error: 0.0237\n",
      "Epoch: 053 | Train Loss: 0.01924 |Test Loss: 0.1939 | Test Error: 0.0228\n",
      "Epoch: 054 | Train Loss: 0.02049 |Test Loss: 0.1922 | Test Error: 0.0241\n",
      "Epoch: 055 | Train Loss: 0.05677 |Test Loss: 0.1754 | Test Error: 0.028\n",
      "Epoch: 056 | Train Loss: 0.03396 |Test Loss: 0.192 | Test Error: 0.0248\n",
      "Epoch: 057 | Train Loss: 0.02734 |Test Loss: 0.1777 | Test Error: 0.0267\n",
      "Epoch: 058 | Train Loss: 0.02928 |Test Loss: 0.1658 | Test Error: 0.0247\n",
      "Epoch: 059 | Train Loss: 0.01557 |Test Loss: 0.1756 | Test Error: 0.0199\n",
      "Epoch: 060 | Train Loss: 0.008555 |Test Loss: 0.1686 | Test Error: 0.0218\n",
      "Epoch: 061 | Train Loss: 0.008804 |Test Loss: 0.1907 | Test Error: 0.0212\n",
      "Epoch: 062 | Train Loss: 0.008258 |Test Loss: 0.2033 | Test Error: 0.0214\n",
      "Epoch: 063 | Train Loss: 0.005655 |Test Loss: 0.2161 | Test Error: 0.0228\n",
      "Epoch: 064 | Train Loss: 0.01068 |Test Loss: 0.1836 | Test Error: 0.0212\n",
      "Epoch: 065 | Train Loss: 0.0183 |Test Loss: 0.1755 | Test Error: 0.0225\n",
      "Epoch: 066 | Train Loss: 0.01572 |Test Loss: 0.1596 | Test Error: 0.0208\n",
      "Epoch: 067 | Train Loss: 0.02312 |Test Loss: 0.1646 | Test Error: 0.0237\n",
      "Epoch: 068 | Train Loss: 0.0154 |Test Loss: 0.1597 | Test Error: 0.0206\n",
      "Epoch: 069 | Train Loss: 0.00889 |Test Loss: 0.1765 | Test Error: 0.022\n",
      "Epoch: 070 | Train Loss: 0.0127 |Test Loss: 0.2548 | Test Error: 0.023\n",
      "Epoch: 071 | Train Loss: 0.01876 |Test Loss: 0.1769 | Test Error: 0.0206\n",
      "Epoch: 072 | Train Loss: 0.01609 |Test Loss: 0.2395 | Test Error: 0.0223\n",
      "Epoch: 073 | Train Loss: 0.01927 |Test Loss: 0.2023 | Test Error: 0.0219\n",
      "Epoch: 074 | Train Loss: 0.01485 |Test Loss: 0.2298 | Test Error: 0.0216\n",
      "Epoch: 075 | Train Loss: 0.01008 |Test Loss: 0.1879 | Test Error: 0.0202\n",
      "Epoch: 076 | Train Loss: 0.01506 |Test Loss: 0.1892 | Test Error: 0.0221\n",
      "Epoch: 077 | Train Loss: 0.01026 |Test Loss: 0.2303 | Test Error: 0.0194\n",
      "Epoch: 078 | Train Loss: 0.01864 |Test Loss: 0.2103 | Test Error: 0.0244\n",
      "Epoch: 079 | Train Loss: 0.0257 |Test Loss: 0.2096 | Test Error: 0.0214\n",
      "Epoch: 080 | Train Loss: 0.03092 |Test Loss: 0.158 | Test Error: 0.0206\n",
      "Epoch: 081 | Train Loss: 0.02219 |Test Loss: 0.156 | Test Error: 0.019\n",
      "Epoch: 082 | Train Loss: 0.0117 |Test Loss: 0.1936 | Test Error: 0.021\n",
      "Epoch: 083 | Train Loss: 0.0116 |Test Loss: 0.21 | Test Error: 0.023\n",
      "Epoch: 084 | Train Loss: 0.01796 |Test Loss: 0.1607 | Test Error: 0.0219\n",
      "Epoch: 085 | Train Loss: 0.01348 |Test Loss: 0.1619 | Test Error: 0.0236\n",
      "Epoch: 086 | Train Loss: 0.007947 |Test Loss: 0.1893 | Test Error: 0.0198\n",
      "Epoch: 087 | Train Loss: 0.02746 |Test Loss: 0.1902 | Test Error: 0.0216\n",
      "Epoch: 088 | Train Loss: 0.02009 |Test Loss: 0.21 | Test Error: 0.0235\n",
      "Epoch: 089 | Train Loss: 0.01366 |Test Loss: 0.191 | Test Error: 0.0227\n",
      "Epoch: 090 | Train Loss: 0.0144 |Test Loss: 0.1782 | Test Error: 0.0198\n",
      "Epoch: 091 | Train Loss: 0.02183 |Test Loss: 0.2523 | Test Error: 0.0259\n",
      "Epoch: 092 | Train Loss: 0.0495 |Test Loss: 0.23 | Test Error: 0.0266\n",
      "Epoch: 093 | Train Loss: 0.03318 |Test Loss: 0.1963 | Test Error: 0.0213\n",
      "Epoch: 094 | Train Loss: 0.01813 |Test Loss: 0.1609 | Test Error: 0.0215\n",
      "Epoch: 095 | Train Loss: 0.01088 |Test Loss: 0.2167 | Test Error: 0.0215\n",
      "Epoch: 096 | Train Loss: 0.01237 |Test Loss: 0.1996 | Test Error: 0.0229\n",
      "Epoch: 097 | Train Loss: 0.01214 |Test Loss: 0.2546 | Test Error: 0.0234\n",
      "Epoch: 098 | Train Loss: 0.008983 |Test Loss: 0.2331 | Test Error: 0.0243\n",
      "Epoch: 099 | Train Loss: 0.01128 |Test Loss: 0.2108 | Test Error: 0.0214\n",
      "Epoch: 100 | Train Loss: 0.009917 |Test Loss: 0.214 | Test Error: 0.0212\n"
     ]
    }
   ],
   "source": [
    "# depth = 5 parameters\n",
    "depth = 5\n",
    "lr = 0.01\n",
    "# initialize model\n",
    "net5 = Network(dim,nclass,width,depth)\n",
    "#send to GPU\n",
    "net5 = net5.to(device)\n",
    "#train it\n",
    "D5 = train_model(net5,batch_size,lr,num_epochs,train_set_mnist,test_set_mnist)\n",
    "#print(f\"Final training loss for depth = 5: {D5[0]:.04}, final test loss for depth = 5: {D5[1]:.04}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss for depth = 1: 0.04195, best test loss for depth = 1: 0.1072\n"
     ]
    }
   ],
   "source": [
    "min = np.argmin(D5[1])\n",
    "print(f\"Best training loss for depth = 1: {D5[0][min]:.04}, best test loss for depth = 1: {D5[1][min]:.04}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f37d392b90>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(D5[0])\n",
    "plt.plot(D5[1])\n",
    "plt.plot(D5[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Train Loss: 1.748 |Test Loss: 1.079 | Test Error: 0.4302\n",
      "Epoch: 002 | Train Loss: 0.602 |Test Loss: 0.3087 | Test Error: 0.0928\n",
      "Epoch: 003 | Train Loss: 0.2589 |Test Loss: 0.2204 | Test Error: 0.0593\n",
      "Epoch: 004 | Train Loss: 0.1849 |Test Loss: 0.2019 | Test Error: 0.0582\n",
      "Epoch: 005 | Train Loss: 0.1436 |Test Loss: 0.1919 | Test Error: 0.0523\n",
      "Epoch: 006 | Train Loss: 0.1108 |Test Loss: 0.141 | Test Error: 0.04\n",
      "Epoch: 007 | Train Loss: 0.09334 |Test Loss: 0.1307 | Test Error: 0.0357\n",
      "Epoch: 008 | Train Loss: 0.07253 |Test Loss: 0.1364 | Test Error: 0.036\n",
      "Epoch: 009 | Train Loss: 0.06176 |Test Loss: 0.1165 | Test Error: 0.0298\n",
      "Epoch: 010 | Train Loss: 0.0561 |Test Loss: 0.132 | Test Error: 0.0335\n",
      "Epoch: 011 | Train Loss: 0.04334 |Test Loss: 0.1237 | Test Error: 0.0304\n",
      "Epoch: 012 | Train Loss: 0.03931 |Test Loss: 0.1388 | Test Error: 0.0335\n",
      "Epoch: 013 | Train Loss: 0.04218 |Test Loss: 0.1237 | Test Error: 0.0288\n",
      "Epoch: 014 | Train Loss: 0.03442 |Test Loss: 0.1325 | Test Error: 0.0292\n",
      "Epoch: 015 | Train Loss: 0.02827 |Test Loss: 0.1253 | Test Error: 0.0261\n",
      "Epoch: 016 | Train Loss: 0.02304 |Test Loss: 0.1288 | Test Error: 0.0263\n",
      "Epoch: 017 | Train Loss: 0.0276 |Test Loss: 0.1339 | Test Error: 0.0287\n",
      "Epoch: 018 | Train Loss: 0.02344 |Test Loss: 0.1373 | Test Error: 0.0279\n",
      "Epoch: 019 | Train Loss: 0.02437 |Test Loss: 0.1396 | Test Error: 0.0293\n",
      "Epoch: 020 | Train Loss: 0.01964 |Test Loss: 0.131 | Test Error: 0.0277\n",
      "Epoch: 021 | Train Loss: 0.01723 |Test Loss: 0.1335 | Test Error: 0.0263\n",
      "Epoch: 022 | Train Loss: 0.01857 |Test Loss: 0.1398 | Test Error: 0.0277\n",
      "Epoch: 023 | Train Loss: 0.01911 |Test Loss: 0.131 | Test Error: 0.0262\n",
      "Epoch: 024 | Train Loss: 0.0173 |Test Loss: 0.1418 | Test Error: 0.0253\n",
      "Epoch: 025 | Train Loss: 0.01587 |Test Loss: 0.1335 | Test Error: 0.0252\n",
      "Epoch: 026 | Train Loss: 0.01553 |Test Loss: 0.1295 | Test Error: 0.0255\n",
      "Epoch: 027 | Train Loss: 0.01511 |Test Loss: 0.1212 | Test Error: 0.0242\n",
      "Epoch: 028 | Train Loss: 0.01351 |Test Loss: 0.1354 | Test Error: 0.0281\n",
      "Epoch: 029 | Train Loss: 0.008829 |Test Loss: 0.1361 | Test Error: 0.0256\n",
      "Epoch: 030 | Train Loss: 0.01157 |Test Loss: 0.1268 | Test Error: 0.0225\n",
      "Epoch: 031 | Train Loss: 0.01256 |Test Loss: 0.1366 | Test Error: 0.0264\n",
      "Epoch: 032 | Train Loss: 0.007689 |Test Loss: 0.1375 | Test Error: 0.0249\n",
      "Epoch: 033 | Train Loss: 0.009651 |Test Loss: 0.1344 | Test Error: 0.025\n",
      "Epoch: 034 | Train Loss: 0.01111 |Test Loss: 0.1451 | Test Error: 0.0251\n",
      "Epoch: 035 | Train Loss: 0.008384 |Test Loss: 0.1356 | Test Error: 0.0234\n",
      "Epoch: 036 | Train Loss: 0.009905 |Test Loss: 0.1351 | Test Error: 0.0244\n",
      "Epoch: 037 | Train Loss: 0.0111 |Test Loss: 0.1538 | Test Error: 0.0253\n",
      "Epoch: 038 | Train Loss: 0.01118 |Test Loss: 0.1318 | Test Error: 0.0211\n",
      "Epoch: 039 | Train Loss: 0.008304 |Test Loss: 0.1347 | Test Error: 0.0221\n",
      "Epoch: 040 | Train Loss: 0.008469 |Test Loss: 0.1413 | Test Error: 0.0247\n",
      "Epoch: 041 | Train Loss: 0.008544 |Test Loss: 0.1311 | Test Error: 0.0238\n",
      "Epoch: 042 | Train Loss: 0.005754 |Test Loss: 0.1364 | Test Error: 0.0221\n",
      "Epoch: 043 | Train Loss: 0.003905 |Test Loss: 0.1632 | Test Error: 0.0244\n",
      "Epoch: 044 | Train Loss: 0.0094 |Test Loss: 0.1361 | Test Error: 0.0233\n",
      "Epoch: 045 | Train Loss: 0.007828 |Test Loss: 0.1416 | Test Error: 0.0232\n",
      "Epoch: 046 | Train Loss: 0.007417 |Test Loss: 0.1409 | Test Error: 0.0231\n",
      "Epoch: 047 | Train Loss: 0.006771 |Test Loss: 0.1632 | Test Error: 0.0263\n",
      "Epoch: 048 | Train Loss: 0.01016 |Test Loss: 0.1442 | Test Error: 0.0234\n",
      "Epoch: 049 | Train Loss: 0.009746 |Test Loss: 0.1472 | Test Error: 0.0248\n",
      "Epoch: 050 | Train Loss: 0.004801 |Test Loss: 0.1555 | Test Error: 0.0238\n",
      "Epoch: 051 | Train Loss: 0.007853 |Test Loss: 0.1407 | Test Error: 0.0206\n",
      "Epoch: 052 | Train Loss: 0.005533 |Test Loss: 0.1267 | Test Error: 0.0206\n",
      "Epoch: 053 | Train Loss: 0.007335 |Test Loss: 0.1401 | Test Error: 0.0226\n",
      "Epoch: 054 | Train Loss: 0.01007 |Test Loss: 0.1394 | Test Error: 0.0255\n",
      "Epoch: 055 | Train Loss: 0.006441 |Test Loss: 0.1331 | Test Error: 0.0219\n",
      "Epoch: 056 | Train Loss: 0.004372 |Test Loss: 0.156 | Test Error: 0.0237\n",
      "Epoch: 057 | Train Loss: 0.007494 |Test Loss: 0.137 | Test Error: 0.0221\n",
      "Epoch: 058 | Train Loss: 0.007179 |Test Loss: 0.1163 | Test Error: 0.0212\n",
      "Epoch: 059 | Train Loss: 0.006967 |Test Loss: 0.1319 | Test Error: 0.021\n",
      "Epoch: 060 | Train Loss: 0.004797 |Test Loss: 0.1403 | Test Error: 0.0198\n",
      "Epoch: 061 | Train Loss: 0.00612 |Test Loss: 0.1364 | Test Error: 0.0202\n",
      "Epoch: 062 | Train Loss: 0.009544 |Test Loss: 0.145 | Test Error: 0.0227\n",
      "Epoch: 063 | Train Loss: 0.007271 |Test Loss: 0.1406 | Test Error: 0.0232\n",
      "Epoch: 064 | Train Loss: 0.01031 |Test Loss: 0.1414 | Test Error: 0.0193\n",
      "Epoch: 065 | Train Loss: 0.008647 |Test Loss: 0.1311 | Test Error: 0.0215\n",
      "Epoch: 066 | Train Loss: 0.005416 |Test Loss: 0.1236 | Test Error: 0.0183\n",
      "Epoch: 067 | Train Loss: 0.005084 |Test Loss: 0.1517 | Test Error: 0.0239\n",
      "Epoch: 068 | Train Loss: 0.006325 |Test Loss: 0.1306 | Test Error: 0.0205\n",
      "Epoch: 069 | Train Loss: 0.006266 |Test Loss: 0.1352 | Test Error: 0.0203\n",
      "Epoch: 070 | Train Loss: 0.002863 |Test Loss: 0.1611 | Test Error: 0.0213\n",
      "Epoch: 071 | Train Loss: 0.00384 |Test Loss: 0.1411 | Test Error: 0.0195\n",
      "Epoch: 072 | Train Loss: 0.004614 |Test Loss: 0.1437 | Test Error: 0.0207\n",
      "Epoch: 073 | Train Loss: 0.007604 |Test Loss: 0.1326 | Test Error: 0.0215\n",
      "Epoch: 074 | Train Loss: 0.006946 |Test Loss: 0.1286 | Test Error: 0.021\n",
      "Epoch: 075 | Train Loss: 0.004473 |Test Loss: 0.136 | Test Error: 0.0201\n",
      "Epoch: 076 | Train Loss: 0.005148 |Test Loss: 0.1404 | Test Error: 0.0211\n",
      "Epoch: 077 | Train Loss: 0.004408 |Test Loss: 0.1409 | Test Error: 0.0205\n",
      "Epoch: 078 | Train Loss: 0.006248 |Test Loss: 0.1427 | Test Error: 0.0223\n",
      "Epoch: 079 | Train Loss: 0.004374 |Test Loss: 0.1551 | Test Error: 0.0221\n",
      "Epoch: 080 | Train Loss: 0.005171 |Test Loss: 0.1507 | Test Error: 0.0223\n",
      "Epoch: 081 | Train Loss: 0.003786 |Test Loss: 0.1425 | Test Error: 0.0213\n",
      "Epoch: 082 | Train Loss: 0.00316 |Test Loss: 0.1566 | Test Error: 0.0203\n",
      "Epoch: 083 | Train Loss: 0.005443 |Test Loss: 0.1486 | Test Error: 0.0229\n",
      "Epoch: 084 | Train Loss: 0.004881 |Test Loss: 0.1307 | Test Error: 0.0205\n",
      "Epoch: 085 | Train Loss: 0.003382 |Test Loss: 0.1747 | Test Error: 0.0221\n",
      "Epoch: 086 | Train Loss: 0.006905 |Test Loss: 0.1378 | Test Error: 0.0194\n",
      "Epoch: 087 | Train Loss: 0.005373 |Test Loss: 0.149 | Test Error: 0.0218\n",
      "Epoch: 088 | Train Loss: 0.002718 |Test Loss: 0.1765 | Test Error: 0.0202\n",
      "Epoch: 089 | Train Loss: 0.00206 |Test Loss: 0.162 | Test Error: 0.0208\n",
      "Epoch: 090 | Train Loss: 0.006818 |Test Loss: 0.1563 | Test Error: 0.021\n",
      "Epoch: 091 | Train Loss: 0.006033 |Test Loss: 0.1838 | Test Error: 0.0228\n",
      "Epoch: 092 | Train Loss: 0.008721 |Test Loss: 0.1512 | Test Error: 0.0211\n",
      "Epoch: 093 | Train Loss: 0.007555 |Test Loss: 0.1259 | Test Error: 0.0206\n",
      "Epoch: 094 | Train Loss: 0.006761 |Test Loss: 0.154 | Test Error: 0.0199\n",
      "Epoch: 095 | Train Loss: 0.007125 |Test Loss: 0.1251 | Test Error: 0.0214\n",
      "Epoch: 096 | Train Loss: 0.006181 |Test Loss: 0.131 | Test Error: 0.0191\n",
      "Epoch: 097 | Train Loss: 0.007032 |Test Loss: 0.1348 | Test Error: 0.0207\n",
      "Epoch: 098 | Train Loss: 0.005268 |Test Loss: 0.1373 | Test Error: 0.0201\n",
      "Epoch: 099 | Train Loss: 0.00446 |Test Loss: 0.1369 | Test Error: 0.019\n",
      "Epoch: 100 | Train Loss: 0.005467 |Test Loss: 0.1153 | Test Error: 0.0179\n"
     ]
    }
   ],
   "source": [
    "# depth = 10 parameters\n",
    "depth = 10\n",
    "lr = 0.001\n",
    "\n",
    "# initialize model\n",
    "net = Network(dim,nclass,width,depth)\n",
    "#send to GPU\n",
    "net = net.to(device)\n",
    "#train it\n",
    "D10 = train_model(net,batch_size,lr,num_epochs,train_set_mnist,test_set_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss for depth = 1: 0.005467, best test loss for depth = 1: 0.1153\n"
     ]
    }
   ],
   "source": [
    "min = np.argmin(D10[1])\n",
    "print(f\"Best training loss for depth = 1: {D10[0][min]:.04}, best test loss for depth = 1: {D10[1][min]:.04}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f371bd2d50>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(D10[0])\n",
    "plt.plot(D10[1])\n",
    "plt.plot(D10[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are summarized in the table below:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> Depth </td>\n",
    "        <td> Train Loss </td>\n",
    "        <td> Test Loss </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 1</td>\n",
    "        <td>- </td>\n",
    "        <td> - </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td>\n",
    "        <td>- </td>\n",
    "        <td> - </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>10</td>\n",
    "        <td>- </td>\n",
    "        <td> - </td>\n",
    "    </tr>\n",
    "\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "a.append(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Part 4: The link between Neural Networks and Gaussian Processes [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.1: Proving the relationship between a Gaussian process and a neural network [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Proper weight scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances are chosen in this way to ensure the stability of the variance of the activations for each layer. This is because, when finding the distribution for each activation in layer l, when the CLT is applied, it leads to a multiplicative factor $N_{l-1}, which would lead to variances that grow with each layer. Hence, in order to stabilise this, the variances of the weight are given this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Derive the GP relation for a single hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the output layer $f_i^{(2)}(x) = \\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x)+b_i^{(2)}$, $i = 1,...,N_2$.\n",
    "\n",
    "Here, the post activations $g_j^{(2)}$ are independent, due to the iid weight and bias parameters.\n",
    "\n",
    "\n",
    "First, we consider each hidden unit in the sum:\n",
    "\n",
    "$\\mathbb{E}[w_{ij}^{(2)}g_{j}^{(1)}(x)] =\\mathbb{E}[w_{ij}^{(2)}]\\mathbb{E}[g_{j}^{(1)}(x)] = 0$, because the weights in this layer are independent from the weights and bias in the previous layer (which determine g), and since $\\mathbb{E}[w_{ij}^{(2)}] = 0$\n",
    "\n",
    "$\\text{Var}(w_{ij}^{(2)}g_{j}^{(1)}(x)) = \\mathbb{E}[(w_{ij}^{(2)}g_{j}^{(1)}(x))^2] = \\mathbb{E}[w_{ij}^{(2)2}]\\mathbb{E}[g_{j}^{(1)}(x)^2] = \\frac{\\sigma_w^{(2)2}}{N_1}\\mathbb{E}[g_{j}^{(1)}(x)^2] $.\n",
    "\n",
    "Then by the CLT, $\\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x)$ is a sum of iid variables with finite variance hence is gaussian with mean 0 and variance $\\sigma_w^{(2)2}\\mathbb{E}[g_{j}^{(1)}(x)^2]$.\n",
    "\n",
    "This means, since $b_i^{(2)}$ is also Gaussian, independent from the sum, that $f_i^{(2)}(x)$ is Gaussian with mean 0 and variance $\\sigma_b^{(2)2} + \\sigma_w^{(2)2}\\mathbb{E}[g^{(1)}(x)^2]$, where we drop the subscript on the expectation since it is the same for all $j$.\n",
    "\n",
    "Now, we generalize to any collection of inputs and outputs eg $f_i^{(2)}(x), f_k^{(2)}(x'),...$.\n",
    "\n",
    "\n",
    "\n",
    "First, by the above, if this collection is stacked into a vector, then this vector will have mean 0 by the above argument.\n",
    "\n",
    "Next, we consider the covariance matrix for this vector:\n",
    "\n",
    "$\\text{Cov}(w_{ij}^{(2)}g_{j}^{(1)}(x),w_{kj}^{(2)}g_{j}^{(1)}(x')) = \\mathbb{E}[w_{ij}^{(2)}g_{j}^{(1)}(x)w_{kj}^{(2)}g_{j}^{(1)}(x')] =  \\mathbb{E}[w_{ij}^{(2)}w_{kj}^{(2)}] \\mathbb{E}[g_{j}^{(1)}(x)g_{j}^{(1)}(x')]$ due to the independence of the weights from the weights and bias in the previous layer as above. Clearly this is 0 unless $i = k$, in which case:\n",
    "\n",
    "$\\text{Cov}(w_{ij}^{(2)}g_{j}^{(1)}(x),w_{ij}^{(2)}g_{j}^{(1)}(x')) = \\frac{\\sigma_w^{(2)2}}{N_1}\\mathbb{E}[g_{j}^{(1)}(x)g_{j}^{(1)}(x')]$.\n",
    "\n",
    "Hence, using the multivariate CLT, $(\\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x),\\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x'),...)$ is Gaussian with mean 0 and covariance matrix defined by\n",
    "\n",
    "$\\text{Cov}(\\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x),\\sum_{j=1}^{N_1}w_{ij}^{(2)}g_{j}^{(1)}(x')) = \\sigma_w^{(2)2}\\mathbb{E}[g^{(1)}(x)g^{(1)}(x')]$\n",
    "\n",
    "\n",
    "Finally, we consider the bias term, which is added to the vector of sums, which we construct to be the vector containing the bias $b_i^{(2)}$ where $i$ corresponds to the output in question. This vector is Gaussian with mean 0 and covariance matrix given by $\\sigma_b^{(2)2}$ for all entries with the same $i$.\n",
    "\n",
    "Thus, $(f_i^{(2)}(x), f_i^{(2)}(x'),...)$ is multivariate Gaussian with mean 0 and covariance $ \\sigma_b^{(2)2} +\\sigma_w^{(2)2}\\mathbb{E}[g^{(1)}(x)g^{(1)}(x')]$. Again, any outputs with non-matching index, regardless of the input, have a covariance of 0.\n",
    "\n",
    "Since this was for any collection, meaning any collection is jointly mulitvariate Gaussian, we conclude that $f_{i}^{(2)}(x)$ follow a Gaussian proess, with mean $\\mu^{1} = 0$, and covariance matrix $K^1$  st $k^1 (x,x')=  \\sigma_b^{(2)2} +\\sigma_w^{(2)2}\\mathbb{E}[g^{(1)}(x)g^{(1)}(x')]$, in the limit that $N_1 \\to \\infty$.\n",
    "\n",
    "Note that in this question, the expectations were taken over the unknown parameters in the previous layer and this layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Why in succession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the limits in succession since, in order to apply the logic iteratively, we require that the previous layer has post activations that are distributed as GPs. In order for this to happen, we require that the previous layer's width has already increased to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Derive the GP relation for multiple hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for the $l$ th layer is $f_i^{(l)}(x) = \\sum_{j=1}^{N_{l-1}}w_{ik}^{(l)}g_j^{(l-1)}(x) + b_i^{(l)}$, where $g_j^{(l-1)}(x) = \\phi(f_j^{(l-1)}(x))$.\n",
    "\n",
    "Taking a very similar approach to before, if we consider each term in the summation $w_{ij}^{(l)}g_j^{(l-1)}$, we see that $\\mathbb{E}[w_{ij}^{(l)}g_j^{(l-1)}] = \\mathbb{E}[w_{ij}^{(l)}]\\mathbb{E}[g_j^{(l-1)}] = 0$ since the expectation of the weight is 0 and the two are independent.\n",
    "\n",
    "Also, \n",
    "\n",
    "$\\text{Cov}(w_{ij}^{(l)}g_{j}^{(l-1)}(x),w_{ij}^{(l)}g_{j}^{(l-1)}(x')) = \\mathbb{E}[w_{ij}^{(l)}g_{j}^{(l-1)}(x)w_{ij}^{(2l)}g_{j}^{(1)}(x')] =  \\mathbb{E}[w_{ij}^{(l)}w_{ij}^{(l)}] \\mathbb{E}[g_{j}^{(l-1)}(x)g_{j}^{(l-1)}(x')] = \\frac{\\sigma_w^{(l)2}}{N_{l-1}}\\mathbb{E}[g_{j}^{(l-1)}(x)g_{j}^{(l-1)}(x')]$ due to the independence of the weights from the weights and bias in the previous layer as above. \n",
    "\n",
    "Since $f_j^{(l-1)}(x)$ is a GP over the inputs, this means that $g_j^{(l-1)}(x)$ are iid given the input. Hence, $w_{ij}^{(l)}g_{j}^{(l-1)}(x)$ are also iid, since $w_{ij}^{(l)} $ are iid, independent from the gs. Thus, when we are considering collections of outputs from a layer, the vectors $(w_{ij}^{(l)}g_{j}^{(l-1)}(x), w_{ij}^{(l)}g_{j}^{(l-1)}(x'),...)^T$ are iid as we vary $j$.\n",
    "\n",
    "Hence we can apply the multivariate CLT, since the covariance matrix is finite, that is, the sum $\\sum_{j=1}^{N_{l-1}}(w_{ij}^{(l)}g_{j}^{(l-1)}(x), w_{ij}^{(l)}g_{j}^{(l-1)}(x'),...)^T$ is Gaussian with mean 0, and covariance matrix defined by $\\sigma_w^{(l)2}\\mathbb{E}[g_{j}^{(l-1)}(x)g_{j}^{(l-1)}(x')]$ (between two of the entries).\n",
    "\n",
    "Finally, as before, we add the bias term vector, where each component is $b_i^{(l)}$, which is Gaussian with mean 0 and covariance matrix given by a matrix of the same dimension as the covariance matrix for the sum, but filled with $\\sigma_b^{(l)2}$.\n",
    "\n",
    "Hence, since this was for any length collection, the collection $f_i^{(l)}(x)$ is a Gaussian process with mean $\\mu_{l-1} = 0$, and covariance matrix $K^{(l-1)}$, which is the matrix of covariances from $k^{(l-1)}(x,x') = \\sigma_b^{(l)2}+\\sigma_w^{(l)2}\\mathbb{E}[g^{(l-1)}(x)g^{(l-1)}(x')]$, where again we drop the subscript since the expectation product is the same for every $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Part 4.2: Analysing the performance of the Gaussian process and a neural network [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall choose the two labels \"dog\" and \"cat\" for this analysis. These correspond to labels 3 and 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# sort out the data\n",
    "train_data = train_set_cifar.data\n",
    "train_labels = np.array(train_set_cifar.targets)\n",
    "#pick 2 classes\n",
    "idx = np.where((train_labels==3) | (train_labels==5) )\n",
    "train_data = train_data[idx]\n",
    "train_labels = train_labels[idx]\n",
    "print(train_labels.shape)\n",
    "\n",
    "#this means we have 10000 data points, so we randomly sample:\n",
    "sample = np.random.randint(0,train_labels.shape[0],size = 1000)\n",
    "train_data = train_data[sample]\n",
    "train_labels = train_labels[sample]\n",
    "\n",
    "#normalize\n",
    "train_data = train_data / 255\n",
    "\n",
    "#put in tensors\n",
    "train_data = torch.tensor(train_data,dtype = torch.float64)\n",
    "train_labels = torch.tensor(train_labels,dtype = torch.float64)\n",
    "\n",
    "#flatten\n",
    "train_data = torch.flatten(train_data,1,3)\n",
    "\n",
    "### Test data ###\n",
    "\n",
    "#test data\n",
    "test_data = test_set_cifar.data\n",
    "test_labels = np.array(test_set_cifar.targets)\n",
    "#pick two classes\n",
    "idx = np.where((test_labels==3) | (test_labels==5) )\n",
    "test_data = test_data[idx]\n",
    "test_labels = test_labels[idx]\n",
    "\n",
    "#normalize\n",
    "test_data = test_data/255\n",
    "\n",
    "#put in tensors\n",
    "test_data = torch.tensor(test_data,dtype = torch.float64)\n",
    "test_labels = torch.tensor(test_labels,dtype = torch.float64)\n",
    "\n",
    "#flatten\n",
    "test_data = torch.flatten(test_data,1,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 0 ###\n",
    "\n",
    "#change the class labels to -0.5 for cat and 0.5 for dog:\n",
    "train_labels[train_labels==3] = -0.5\n",
    "train_labels[train_labels==5] = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3072])\n",
      "torch.Size([1000])\n",
      "torch.Size([2000, 3072])\n",
      "torch.Size([2000])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall change the output to be -0.5 for cat and 0.5 for dog, before proceeding with the analysis. Then, since we are going to be taking a regression output, whenever the model returns an output less than 0, we classify as cat, and anything greater than 0 as dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2 ###\n",
    "\n",
    "\n",
    "\n",
    "def kernel(L,sigma_w,sigma_b,X1,X2):\n",
    "    \"\"\"\n",
    "        Function that calculates the kernel for layer L\n",
    "\n",
    "        Args:\n",
    "        L - The number of layers\n",
    "        sigma_w - variance of weights \n",
    "        sigma_b - variance of bias\n",
    "        X1 - first dataset, size M1 x N0\n",
    "        X2 - second dataset, size M2 x N0 \n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Kernel matrix of shape (n, m).\n",
    "        \"\"\"\n",
    "    N0 = X1.shape[1]\n",
    "    #K0:\n",
    "    K = sigma_b + sigma_w/N0 * torch.matmul(X1,X2.t())\n",
    "    #this ensures the inner product works as intended\n",
    "    K_x1x1 = sigma_b + sigma_w/N0 * torch.sum(torch.square(X1),dim=1).unsqueeze(1)\n",
    "    K_x2x2 = sigma_b + sigma_w/N0 * torch.sum(torch.square(X2),dim=1).unsqueeze(1)\n",
    "    #now iteratively calculate:\n",
    "    for i in range(L):\n",
    "        #theta for previous layer\n",
    "        #we get some NaNs start to appear, so clamp this\n",
    "        costheta = torch.clamp(K/torch.sqrt(torch.matmul(K_x1x1,K_x2x2.t())),min = -1+1e-6, max = 1-1e-6)\n",
    "\n",
    "        theta = torch.arccos(costheta)\n",
    "        #new K\n",
    "        K = sigma_b + sigma_w/(2 * torch.pi) * torch.sqrt(torch.matmul(K_x1x1,K_x2x2.t())) * (torch.sin(theta) + (torch.pi - theta)*costheta)\n",
    "        #update inner product matrices. Noticing that in the formula, for (x,x), theta = arccos(1) = 0\n",
    "        #meaning K(X,X) = sigma_b + sigma_w/2K\n",
    "        K_x1x1 = sigma_b + sigma_w/2 * K_x1x1\n",
    "        K_x2x2 = sigma_b + sigma_w/2 * K_x2x2\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP:\n",
    "    \n",
    "    def __init__(self, kernel: callable):\n",
    "        \"\"\"\n",
    "        Initialize the Gaussian Process (GP) with a specified kernel.\n",
    "\n",
    "        Args:\n",
    "        kernel (callable): The kernel function to use in the GP.\n",
    "        \"\"\"\n",
    "        self.k = kernel\n",
    "\n",
    "    def predict(self, x_star, sigma_w, sigma_b, L, X=None, y=None, size=1, sigma=0 ):\n",
    "        \"\"\"\n",
    "        Given observations (X, y) and test points x_star, fit a GP model\n",
    "        and draw posterior samples for f(x_star) from the fitted model.\n",
    "\n",
    "        Args:\n",
    "        x_star (torch.Tensor): Test points at which predictions will be made.\n",
    "        sigma_w (float): weight variance\n",
    "        sigma_b(float): bias variance\n",
    "        L (int)- Layer\n",
    "        X (torch.Tensor): Observed features.\n",
    "        y (torch.Tensor): Observed response variables.\n",
    "        size (int): Number of posterior samples to draw.\n",
    "        sigma (float): Noise level in observations.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Posterior samples for f(x_star).\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute kernel matrices\n",
    "        #same format as the one we just made\n",
    "        k_xs_x = self.k(L,sigma_w,sigma_b,x_star,X)\n",
    "        k_x_xs = self.k(L,sigma_w,sigma_b,X,x_star)\n",
    "        k_x_x = self.k(L,sigma_w,sigma_b,X,X)\n",
    "        k_xs_xs = self.k(L,sigma_w,sigma_b,x_star,x_star)\n",
    "   \n",
    "\n",
    "        cov_x_x = k_x_x + sigma *  torch.eye(X.shape[0]) \n",
    "        # Compute posterior mean and covariance\n",
    "        posterior_mean = torch.linalg.matmul(k_xs_x ,torch.linalg.solve(cov_x_x,y))\n",
    "        posterior_var = k_xs_xs - torch.matmul(k_xs_x,torch.linalg.solve(cov_x_x,k_x_xs))\n",
    "        print(posterior_var)\n",
    "        # -----------------------------------------------------------------------------------\n",
    "        # Enforce symmetry and positive definiteness that may be lost due to numerical errors\n",
    "        posterior_var = (posterior_var + posterior_var.T) / 2  # Enforce symmetry\n",
    "        # Add a small amount of noise to the diagonal to make the covariance matrix positive definite\n",
    "        posterior_var = posterior_var + 1e-6 * torch.eye(posterior_var.shape[0])\n",
    "        # -----------------------------------------------------------------------------------\n",
    "        \n",
    "        self.posterior_mean = posterior_mean\n",
    "        self.posterior_var = posterior_var\n",
    "        \n",
    "        # Draw samples from the posterior distribution\n",
    "        y_star = torch.distributions.MultivariateNormal(posterior_mean, posterior_var).sample((size,))\n",
    "\n",
    "        return y_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05],\n",
      "        [9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05],\n",
      "        [9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05],\n",
      "        ...,\n",
      "        [9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05],\n",
      "        [9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05],\n",
      "        [9.9905e-05, 9.9905e-05, 9.9905e-05,  ..., 9.9905e-05, 9.9905e-05,\n",
      "         9.9905e-05]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Another hint: when  computing [ K^L(X,X) + noise^2 Id ]^-1 y and  [ K^L(X,X) + noise^2 Id ]^-1 K^L(X,X*)\n",
    "# You can TRY cholesky solve as it should be p.d. (except case for numerical errors) - maybe you can use try:/except:\n",
    "# You can also try to enforce symmetry in posterior covariance by doing (K + K.t())/2\n",
    "\n",
    "Gauss = GP(kernel)\n",
    "a = Gauss.predict(test_data, 0.1,0.1,20,train_data, train_labels,1000,sigma = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0052, 0.0052, 0.0052,  ..., 0.0052, 0.0052, 0.0052])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b =torch.mean(a,axis = 0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000])\n",
      "torch.Size([2000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[b>0] = 5\n",
    "b[b<0] = 3\n",
    "print(b.shape)\n",
    "print(test_labels.shape)\n",
    "sum(b==test_labels)/b.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
